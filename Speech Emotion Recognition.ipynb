{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9271e9c-a7d2-4320-8f1a-957b8c91a0c5",
   "metadata": {},
   "source": [
    "## 1. Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54dc98-e37a-4f42-85e3-9eec8f7841c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing librosa\n",
    "!pip install librosa\n",
    "\n",
    "# Installing tensorflow\n",
    "!pip install \"tensorflow<2.11\"\n",
    "\n",
    "!pip install pandas\n",
    "\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ef4a6-e0a5-445f-9938-b92d3bb28c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing os for file management\n",
    "import os\n",
    "\n",
    "# Importing numpy\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Importin librosa, soundfile, wiener\n",
    "import librosa\n",
    "import soundfile\n",
    "from scipy.signal import wiener\n",
    "\n",
    "# Importing tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing neural netwrok components\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D ,Bidirectional ,LSTM, Dense, Flatten, Reshape, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2 \n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Importing OneHotencoder and train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb01e34-5433-4b3e-9c8c-01fadf46615e",
   "metadata": {},
   "source": [
    "## 2. Prepocessing and making the labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae3648-3c36-4432-8f1f-846eeb00a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Wiener filtering with safety check\n",
    "def safe_wiener(audio_signal):\n",
    "    if len(audio_signal) > 1:\n",
    "        return wiener(audio_signal)\n",
    "    return audio_signal  # If the signal is too short, skip filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f30a6d3-e1a4-44e8-bff3-ffaad0cd5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.signal import wiener\n",
    "\n",
    "# Path to the EmoDB dataset\n",
    "source_dir = \"./emodb\"\n",
    "\n",
    "# Emotion mapping based on EmoDB file naming conventions\n",
    "emotion_map = {\n",
    "    'W': 'angry',\n",
    "    'L': 'boredom',\n",
    "    'E': 'disgust',\n",
    "    'A': 'fearful',\n",
    "    'F': 'happy',\n",
    "    'T': 'sad',\n",
    "    'N': 'neutral'\n",
    "}\n",
    "\n",
    "audio_data = []\n",
    "labels = []\n",
    "\n",
    "# Function for Wiener filtering with safety check\n",
    "def safe_wiener(audio_signal):\n",
    "    if len(audio_signal) > 1:\n",
    "        return wiener(audio_signal)\n",
    "    return audio_signal  # If the signal is too short, skip filtering\n",
    "\n",
    "\n",
    "processed_files = []\n",
    "skipped_files = []\n",
    "\n",
    "for filename in os.listdir(source_dir):\n",
    "    emotion_key = filename[5]  # Emotion code is the 6th character\n",
    "    emotion_label = emotion_map.get(emotion_key)\n",
    "                \n",
    "    # Load the audio file\n",
    "    audio_path = os.path.join(source_dir, filename)\n",
    "    audio, sr = librosa.load(audio_path, sr=None)  # Load with original sampling rate\n",
    "\n",
    "    # Resampling to 44.1 kHz\n",
    "    target_sr = 44100\n",
    "    if sr != target_sr:\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "    \n",
    "    # Silence Trimming\n",
    "    audio, _ = librosa.effects.trim(audio)\n",
    "    \n",
    "    # Wiener Filtering for noise reduction\n",
    "    audio = safe_wiener(audio)\n",
    "    \n",
    "    # Zero Padding or truncating to 3 seconds (132300 samples at 44.1 kHz)\n",
    "    desired_length = target_sr * 3  # 3 seconds of audio\n",
    "    if len(audio) < desired_length:\n",
    "        audio = np.pad(audio, (0, desired_length - len(audio)), mode=\"constant\")\n",
    "    else:\n",
    "        audio = audio[:desired_length]\n",
    "\n",
    "    # Convert to Mel-Spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=target_sr,\n",
    "        n_mels=128,\n",
    "        hop_length=512,\n",
    "        win_length=2048,  # Hanning window length\n",
    "        window=\"hann\"  # Apply Hanning window\n",
    "    )\n",
    "    \n",
    "    # Convert to log scale (decibels)\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    # Append the processed log-mel spectrogram and label to lists\n",
    "    audio_data.append(log_mel_spectrogram)\n",
    "    labels.append(emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad52fdc-5b86-474b-a8b5-bd05a562c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and labels\n",
    "X = np.array(audio_data)\n",
    "\n",
    "X = np.expand_dims(X, axis = -1)\n",
    "\n",
    "y = np.array(labels)\n",
    "\n",
    "# Encoding the labels\n",
    "encode = OneHotEncoder(sparse_output=False)\n",
    "y_encode = encode.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Train-test splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encode, test_size=0.2, random_state=42, stratify=y_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8010676-b10b-466b-bc39-ad4b75dc2440",
   "metadata": {},
   "source": [
    "## 3. Building and Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be154e-99ad-40f3-82b6-ee726dc17b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape = (128, 259, 1)))\n",
    "\n",
    "# 1st Convolution Layer\n",
    "model.add(Conv2D(64, kernel_size = (9,9), strides = (2,2), activation = \"relu\", padding = \"same\", kernel_regularizer = l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (2,2), strides = (2,2), padding = \"same\"))\n",
    "\n",
    "# 2nd Convolution layer\n",
    "model.add(Conv2D(64, kernel_size = (7,7), strides = (1,1), activation = \"relu\", padding = \"same\", kernel_regularizer = l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (4,4), strides = (4,4), padding = \"same\"))\n",
    "\n",
    "# 3rd Convolution Layer\n",
    "model.add(Conv2D(128, kernel_size = (5,5), strides = (1,1), activation = \"relu\", padding = \"same\", kernel_regularizer = l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (4,4), strides = (4,4), padding = \"same\"))\n",
    "\n",
    "# 4th Convolution layer\n",
    "model.add(Conv2D(128, kernel_size = (3,3), strides = (1,1), activation = \"relu\", padding = \"same\", kernel_regularizer = l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (4,4), strides = (4,4), padding = \"same\"))\n",
    "\n",
    "conv_output_shape = model.output_shape[1:]  # Output shape from Conv2D layers\n",
    "\n",
    "# Reshape layer before BiLSTM\n",
    "model.add(Reshape((conv_output_shape[0], conv_output_shape[1] * conv_output_shape[2])))\n",
    "\n",
    "# BiLSTM Layer\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "\n",
    "# Dense Layer\n",
    "model.add(Dense(8, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = 0.0001), loss = CategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf9f20-9d67-4bfa-b64b-76837d2b840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33026cb5-62de-4770-958a-d9e5b5eb4d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traing the model\n",
    "model.fit(X_train, y_train, batch_size = 16, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b5ea5-075e-4ced-803b-d1017918216c",
   "metadata": {},
   "source": [
    "## 4. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b93a4-a8ad-4086-9bf2-0ae81df13cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions and true labels to class indices\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes, normalize='true')\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3e0ee-6425-42d4-821c-439426013b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(y_test_classes, y_pred_classes, target_names=encode.categories_[0])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8804e960-2c0e-44ec-9834-ebb529b6fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/first_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335e6aa-027a-4e46-a64c-d2c1ae67fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"models/first_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
